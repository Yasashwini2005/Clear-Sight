{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hycCjY3iJIPs",
        "outputId": "f02d97a3-e283-4036-c1ea-7142c54a3002"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rAnk76ECJFYB",
        "outputId": "c0092f54-68ba-49f4-b65c-818fcd308846"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available:  1\n",
            "Using GPU:  /device:GPU:0\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Total images loaded: 4000\n",
            "\n",
            "Training VGG16 model...\n",
            "Epoch 1/16\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 155ms/step - accuracy: 0.5920 - loss: 0.6597 - val_accuracy: 0.7525 - val_loss: 0.4706\n",
            "Epoch 2/16\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 158ms/step - accuracy: 0.7470 - loss: 0.4921 - val_accuracy: 0.7975 - val_loss: 0.4469\n",
            "Epoch 3/16\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 157ms/step - accuracy: 0.7835 - loss: 0.4516 - val_accuracy: 0.7950 - val_loss: 0.4288\n",
            "Epoch 4/16\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 157ms/step - accuracy: 0.7914 - loss: 0.4363 - val_accuracy: 0.8050 - val_loss: 0.4110\n",
            "Epoch 5/16\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 156ms/step - accuracy: 0.8097 - loss: 0.4104 - val_accuracy: 0.7625 - val_loss: 0.4361\n",
            "Epoch 6/16\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 156ms/step - accuracy: 0.8190 - loss: 0.4095 - val_accuracy: 0.8000 - val_loss: 0.3939\n",
            "Epoch 7/16\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 156ms/step - accuracy: 0.8196 - loss: 0.3993 - val_accuracy: 0.8175 - val_loss: 0.3676\n",
            "Epoch 8/16\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 156ms/step - accuracy: 0.8214 - loss: 0.3982 - val_accuracy: 0.8350 - val_loss: 0.3397\n",
            "Epoch 9/16\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 156ms/step - accuracy: 0.8311 - loss: 0.3586 - val_accuracy: 0.8575 - val_loss: 0.3208\n",
            "Epoch 10/16\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 156ms/step - accuracy: 0.8524 - loss: 0.3286 - val_accuracy: 0.8775 - val_loss: 0.3109\n",
            "Epoch 11/16\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 155ms/step - accuracy: 0.8645 - loss: 0.3122 - val_accuracy: 0.8675 - val_loss: 0.3029\n",
            "Epoch 12/16\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 157ms/step - accuracy: 0.8827 - loss: 0.2840 - val_accuracy: 0.8250 - val_loss: 0.3889\n",
            "Epoch 13/16\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 156ms/step - accuracy: 0.8967 - loss: 0.2532 - val_accuracy: 0.9200 - val_loss: 0.2455\n",
            "Epoch 14/16\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 156ms/step - accuracy: 0.9175 - loss: 0.2143 - val_accuracy: 0.8750 - val_loss: 0.2838\n",
            "Epoch 15/16\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 155ms/step - accuracy: 0.9237 - loss: 0.1854 - val_accuracy: 0.9025 - val_loss: 0.2638\n",
            "Epoch 16/16\n",
            "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 156ms/step - accuracy: 0.9471 - loss: 0.1488 - val_accuracy: 0.9075 - val_loss: 0.2426\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Saving the TensorFlow model to Google Drive...\n",
            "TensorFlow model saved at /content/drive/MyDrive/my_glaucoma_dataset/vgg16_glaucoma_model.h5\n",
            "\n",
            "Saving the model as a .pkl file...\n",
            "Pickle model saved at /content/drive/MyDrive/my_glaucoma_dataset/vgg16_glaucoma_model.pkl\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 838ms/step - accuracy: 0.8741 - loss: 0.3026\n",
            "\n",
            "Test Accuracy: 0.91\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import tensorflow as tf\n",
        "import pickle\n",
        "\n",
        "# Enable GPU logging for device placement\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
        "print(\"Using GPU: \", tf.test.gpu_device_name())\n",
        "\n",
        "def load_dataset(dataset_path, max_images_per_class=2000):\n",
        "    image_paths = []\n",
        "    labels = []\n",
        "    class_mapping = {'Non-Glaucomous': 0, 'Glaucomous': 1}  # Update based on folder names\n",
        "\n",
        "    for class_name, label in class_mapping.items():\n",
        "        folder_path = os.path.join(dataset_path, class_name)\n",
        "        if not os.path.exists(folder_path):\n",
        "            print(f\"Warning: Folder {class_name} not found at {folder_path}\")\n",
        "            continue\n",
        "\n",
        "        all_files = [f for f in os.listdir(folder_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "        all_files = sorted(all_files)[:max_images_per_class]\n",
        "\n",
        "        for filename in all_files:\n",
        "            image_path = os.path.join(folder_path, filename)\n",
        "            image_paths.append(image_path)\n",
        "            labels.append(label)\n",
        "\n",
        "    print(f\"Total images loaded: {len(image_paths)}\")\n",
        "    return image_paths, labels\n",
        "\n",
        "def preprocess_image(image_path, target_size=(224, 224)):\n",
        "    image = cv2.imread(image_path)\n",
        "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    resized_image = cv2.resize(image_rgb, target_size, interpolation=cv2.INTER_AREA)\n",
        "    normalized_image = resized_image.astype(np.float32) / 255.0\n",
        "    return normalized_image\n",
        "\n",
        "def prepare_data(image_paths, labels, target_size=(224, 224)):\n",
        "    images = [preprocess_image(path, target_size) for path in image_paths]\n",
        "    images = np.array(images)\n",
        "    labels = np.array(labels)\n",
        "    return images, labels\n",
        "\n",
        "def split_dataset(image_paths, labels, test_size=0.2, val_size=0.5):\n",
        "    X_train, X_temp, y_train, y_temp = train_test_split(image_paths, labels, test_size=test_size, stratify=labels, random_state=42)\n",
        "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=val_size, stratify=y_temp, random_state=42)\n",
        "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
        "\n",
        "def create_vgg16_model(input_shape=(224, 224, 3)):\n",
        "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = base_model(inputs, training=False)\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(256, activation='relu')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    outputs = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    model = Model(inputs, outputs)\n",
        "    model.compile(optimizer=Adam(1e-4), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Dataset path\n",
        "dataset_path = \"/content/drive/MyDrive/my_glaucoma_dataset\"\n",
        "\n",
        "# Define the path to save the model\n",
        "model_save_path = \"/content/drive/MyDrive/my_glaucoma_dataset/vgg16_glaucoma_model.h5\"\n",
        "\n",
        "# Load dataset\n",
        "image_paths, labels = load_dataset(dataset_path, max_images_per_class=2000)\n",
        "\n",
        "# Split dataset\n",
        "X_train_paths, X_val_paths, X_test_paths, y_train, y_val, y_test = split_dataset(image_paths, labels)\n",
        "\n",
        "# Preprocess data\n",
        "X_train, y_train = prepare_data(X_train_paths, y_train)\n",
        "X_val, y_val = prepare_data(X_val_paths, y_val)\n",
        "X_test, y_test = prepare_data(X_test_paths, y_test)\n",
        "\n",
        "# Create and train VGG16 model\n",
        "input_shape = (224, 224, 3)\n",
        "vgg16_model = create_vgg16_model(input_shape)\n",
        "\n",
        "print(\"\\nTraining VGG16 model...\")\n",
        "history_vgg16 = vgg16_model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=16,\n",
        "    batch_size=8,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Save the model in TensorFlow format\n",
        "print(\"\\nSaving the TensorFlow model to Google Drive...\")\n",
        "vgg16_model.save(model_save_path)\n",
        "print(f\"TensorFlow model saved at {model_save_path}\")\n",
        "\n",
        "# Save the model as a .pkl file\n",
        "pkl_model_save_path = \"/content/drive/MyDrive/my_glaucoma_dataset/vgg16_glaucoma_model.pkl\"\n",
        "print(\"\\nSaving the model as a .pkl file...\")\n",
        "with open(pkl_model_save_path, 'wb') as f:\n",
        "    pickle.dump(vgg16_model, f)\n",
        "print(f\"Pickle model saved at {pkl_model_save_path}\")\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = vgg16_model.evaluate(X_test, y_test, verbose=1)\n",
        "print(f\"\\nTest Accuracy: {test_accuracy:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Path to the saved model\n",
        "model_save_path = \"/content/drive/MyDrive/my_glaucoma_dataset/vgg16_glaucoma_model.h5\"\n",
        "\n",
        "# Load the saved model\n",
        "vgg16_model = load_model(model_save_path)\n",
        "print(\"Model loaded successfully!\")\n",
        "\n",
        "# Function to preprocess a single image\n",
        "def preprocess_input_image(image_path, target_size=(224, 224)):\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is None:\n",
        "        raise ValueError(f\"Image not found at path: {image_path}\")\n",
        "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    resized_image = cv2.resize(image_rgb, target_size, interpolation=cv2.INTER_AREA)\n",
        "    normalized_image = resized_image.astype(np.float32) / 255.0\n",
        "    return np.expand_dims(normalized_image, axis=0)  # Add batch dimension\n",
        "\n",
        "# Function to make a prediction\n",
        "def predict_image_class(image_path):\n",
        "    # Preprocess the image\n",
        "    preprocessed_image = preprocess_input_image(image_path)\n",
        "\n",
        "    # Make prediction\n",
        "    prediction = vgg16_model.predict(preprocessed_image)\n",
        "\n",
        "    # Interpret the result\n",
        "    class_mapping = {0: \"Non-Glaucomous\", 1: \"Glaucomous\"}\n",
        "    predicted_class = int(np.round(prediction[0][0]))  # Convert probability to binary class\n",
        "    confidence = prediction[0][0] * 100 if predicted_class == 1 else (1 - prediction[0][0]) * 100\n",
        "\n",
        "    print(f\"Prediction: {class_mapping[predicted_class]}\")\n",
        "    print(f\"Confidence: {confidence:.2f}%\")\n",
        "    return class_mapping[predicted_class], confidence\n",
        "\n",
        "# Example usage\n",
        "image_path = \"/content/drive/MyDrive/my_glaucoma_dataset/Non-Glaucomous/002.jpg\"  # Replace with the path to your input image\n",
        "predicted_class, confidence = predict_image_class(image_path)\n"
      ],
      "metadata": {
        "id": "eEHxydEdnTmY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22452689-bef6-43dc-e6f0-9a9199e922fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded successfully!\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 641ms/step\n",
            "Prediction: Non-Glaucomous\n",
            "Confidence: 83.43%\n"
          ]
        }
      ]
    }
  ]
}